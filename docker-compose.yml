version: '3'
services:
  nodejs-server:
    build:
      context: .
      dockerfile: ./kafka-server/Dockerfile
    ports:
      - "3000:3000"
    networks:
      - my-network
  pyspark-script:
    build:
      context: .
      dockerfile: ./pyspark/Dockerfile
    depends_on:
      - nodejs-server
    networks:
      - my-network
  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://localhost:9093,OUTSIDE://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "kafka-topic:1:1" 
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
    ports:
      - "9092:9092"
      - "9093:9093"
    expose:
      - "9092"
      - "9093"
    networks:
      - my-network
    depends_on:
      - zookeeper

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    networks:
      - my-network

  mongodb:
    build:
      context: .
      dockerfile: ./mongo-server/Dockerfile
    ports:
      - "27017:27017"
    networks:
      - my-network

networks:
  my-network:
